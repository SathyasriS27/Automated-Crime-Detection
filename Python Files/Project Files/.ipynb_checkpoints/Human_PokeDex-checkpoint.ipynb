{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVTet-sDU9kT",
    "outputId": "7a1afa34-e14c-4dc0-dd51-aa49ff888f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Using legacy 'setup.py install' for imutils, since package 'wheel' is not installed.\n",
      "Installing collected packages: imutils\n",
      "    Running setup.py install for imutils: started\n",
      "    Running setup.py install for imutils: finished with status 'done'\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdo-ICq615RJ",
    "outputId": "367548b0-a0c6-48f5-ae29-f7023484388f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.1.48-cp39-cp39-win_amd64.whl (41.2 MB)\n",
      "Collecting numpy>=1.19.3\n",
      "  Downloading numpy-1.20.1-cp39-cp39-win_amd64.whl (13.7 MB)\n",
      "Installing collected packages: numpy, opencv-contrib-python\n",
      "Successfully installed numpy-1.20.1 opencv-contrib-python-4.5.1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cjn5BlIo1ekW"
   },
   "source": [
    "# **Extract embeddings from face dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XN6NxT6A0FZ8"
   },
   "outputs": [],
   "source": [
    "# Importing all necessary packages\n",
    "\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P3w76101_7J",
    "outputId": "988ed5b9-4b61-4c8d-bb2a-c1b0b5e862cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face detector...\n",
      "\n",
      "Loading face recognizer...\n"
     ]
    }
   ],
   "source": [
    "# Load face detector\n",
    "\n",
    "print(\"Loading face detector...\")\n",
    "\n",
    "protoPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\face_detection_model', 'deploy.prototxt'])\n",
    "modelPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\face_detection_model', 'res10_300x300_ssd_iter_140000.caffemodel'])\n",
    "\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "\n",
    "# Load face recognizer\n",
    "\n",
    "print(\"\\nLoading face recognizer...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\openface_nn4.small2.v1.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDk_iHf1OO2Q",
    "outputId": "9b77a285-4bd2-43fe-bb62-ea998bd41965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantifying faces...\n"
     ]
    }
   ],
   "source": [
    "# Entering paths to our images dataset\n",
    "\n",
    "print('\\nQuantifying faces...')\n",
    "imagePaths = list(paths.list_images(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Datasets'))\n",
    "\n",
    "knownEmbeddings = []\n",
    "knownNames = []\n",
    "\n",
    "# Total number of faces\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "036MFBrCQFz6",
    "outputId": "9ae917bc-1217-44c2-e15f-8ee733a0c8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/46\n",
      "Processing image 2/46\n",
      "Processing image 3/46\n",
      "Processing image 4/46\n",
      "Processing image 5/46\n",
      "Processing image 6/46\n",
      "Processing image 7/46\n",
      "Processing image 8/46\n",
      "Processing image 9/46\n",
      "Processing image 10/46\n",
      "Processing image 11/46\n",
      "Processing image 12/46\n",
      "Processing image 13/46\n",
      "Processing image 14/46\n",
      "Processing image 15/46\n",
      "Processing image 16/46\n",
      "Processing image 17/46\n",
      "Processing image 18/46\n",
      "Processing image 19/46\n",
      "Processing image 20/46\n",
      "Processing image 21/46\n",
      "Processing image 22/46\n",
      "Processing image 23/46\n",
      "Processing image 24/46\n",
      "Processing image 25/46\n",
      "Processing image 26/46\n",
      "Processing image 27/46\n",
      "Processing image 28/46\n",
      "Processing image 29/46\n",
      "Processing image 30/46\n",
      "Processing image 31/46\n",
      "Processing image 32/46\n",
      "Processing image 33/46\n",
      "Processing image 34/46\n",
      "Processing image 35/46\n",
      "Processing image 36/46\n",
      "Processing image 37/46\n",
      "Processing image 38/46\n",
      "Processing image 39/46\n",
      "Processing image 40/46\n",
      "Processing image 41/46\n",
      "Processing image 42/46\n",
      "Processing image 43/46\n",
      "Processing image 44/46\n",
      "Processing image 45/46\n",
      "Processing image 46/46\n"
     ]
    }
   ],
   "source": [
    "# Loop over all image paths\n",
    "\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "  print(\"Processing image {}/{}\".format(i + 1, len(imagePaths)))                  # Extract the person name from the image path\n",
    "  name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "  image = cv2.imread(imagePath)                                                   # Load the image\n",
    "  image = imutils.resize(image, width=600)                                        # Resize to (600, 600)\n",
    "  (h, w) = image.shape[:2]                                                        # Store image dimensions\n",
    "  imageBlob = cv2.dnn.blobFromImage(                                              # Construct a blob from the image\n",
    "  \tcv2.resize(image, (300, 300)), 1.0, (300, 300),\n",
    "  \t(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "  detector.setInput(imageBlob)                                                    # Face Detector to localize face in an image\n",
    "  detections = detector.forward()       \n",
    "\n",
    "  if len(detections) > 0:                                                         # Ensure at least one face was found\n",
    "    i = np.argmax(detections[0, 0, :, 2])\n",
    "    confidence = detections[0, 0, i, 2]        \n",
    "\n",
    "    if (confidence > 0.1):                                                          # Filtering weak detections\n",
    "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\t\t\n",
    "      face = image[startY:endY, startX:endX]\n",
    "      (fH, fW) = face.shape[:2]\n",
    "\t\t\t\n",
    "      if (fW < 20 or fH < 20):\n",
    "        continue    \n",
    "\n",
    "      faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), \n",
    "                                       swapRB=True, crop=False)                   # Create blob\n",
    "\n",
    "      embedder.setInput(faceBlob)\n",
    "      vec = embedder.forward()\n",
    "\n",
    "      knownNames.append(name)                                                     # Append name to list\n",
    "      knownEmbeddings.append(vec.flatten())                                       # Append flattened embedding to list\n",
    "      total += 1                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glLTq5YeYOLZ",
    "outputId": "fee56187-0fe8-476b-fc39-201c9947d5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing 46 encodings:\n",
      "\n",
      "Serialized 46 encodings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save (pickle) the embeddings and the names\n",
    "\n",
    "print('Serializing {} encodings:\\n'.format(total))\n",
    "\n",
    "data = {'embeddings': knownEmbeddings, 'names': knownNames}                       # Saved as a dictionary/ HashMap\n",
    "f = open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Output Embeddings\\embeddings.pickle', 'wb')\n",
    "f.write(pickle.dumps(data))                                                       # Stored as a ByteStream\n",
    "f.close()\n",
    "print(\"Serialized {} encodings.\\n\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dlH_sXrZmx3"
   },
   "source": [
    "# **Train the face recognition model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\users\\yash' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9EeL68fqZmUy"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import argparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQXtEKrgdXGy",
    "outputId": "070fd999-812a-49cf-f94a-fb3c4458b482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face embeddings:\n",
      "\n",
      "Loaded.\n",
      "\n",
      "\n",
      "Encoding labels:\n",
      "\n",
      "\n",
      "Labels encoded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading face embeddings:\\n\")\n",
    "data = pickle.loads(open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Output Embeddings\\embeddings.pickle', 'rb').read())\n",
    "print(\"Loaded.\\n\\n\")\n",
    "\n",
    "print(\"Encoding labels:\\n\")\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(data['names'])\n",
    "print(\"\\nLabels encoded.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QoQw-Auiolr",
    "outputId": "a7a89bf4-9574-4e06-9acf-f25e435446f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "\n",
      "Model trained.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\\n\")\n",
    "recognizer = SVC(C = 1.0, kernel = \"linear\", probability = True)\n",
    "recognizer.fit(data[\"embeddings\"], labels)\n",
    "print(\"\\nModel trained.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q6RnEopljrS2"
   },
   "outputs": [],
   "source": [
    "# Save the actual face recognition model\n",
    "f = open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Trained Models\\recognizer.pickle', \"wb\")\n",
    "f.write(pickle.dumps(recognizer))\n",
    "f.close()\n",
    "\n",
    "# Save the label encoder\n",
    "f = open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Trained Models\\le.pickle', \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmQiypWqk1MV"
   },
   "source": [
    "# **Recognise faces using OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tDVTA-esk6Wo"
   },
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXSzYgIyk-za",
    "outputId": "47e69b48-28f4-4109-8c3b-79d09b794eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face detector...\n",
      "\n",
      "Loaded face detector.\n",
      "\n",
      "\n",
      "Loading face recognizer...\n",
      "\n",
      "Loaded Face Recognizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load our serialized face detector\n",
    "\n",
    "print(\"Loading face detector...\\n\")\n",
    "protoPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\face_detection_model', 'deploy.prototxt'])\n",
    "modelPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\face_detection_model', 'res10_300x300_ssd_iter_140000.caffemodel'])\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "print(\"Loaded face detector.\\n\")\n",
    "\n",
    "# Load our serialized face embedding model\n",
    "print(\"\\nLoading face recognizer...\\n\")\n",
    "embedder = cv2.dnn.readNetFromTorch(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\opencv-face-recognition\\openface_nn4.small2.v1.t7')\n",
    "print(\"Loaded Face Recognizer.\\n\")\n",
    "\n",
    "# Load the SVM Model and LabelEncoder\n",
    "recognizer = pickle.loads(open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Trained Models\\recognizer.pickle', \"rb\").read())\n",
    "le = pickle.loads(open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab Docs\\Project Files\\Trained Models\\le.pickle', \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "ope1aUvrlJth",
    "outputId": "80c8ee5d-9ac2-4b57-84cb-da61fa6029a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video stream...\n",
      "\n",
      "Elapsed time: 328.31\n",
      "Approx. FPS: 13.70\n"
     ]
    }
   ],
   "source": [
    "# Initialize the video stream, then allow the camera sensor to warm up\n",
    "\n",
    "print(\"Starting video stream...\\n\")\n",
    "\n",
    "vs = VideoStream(src = 0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Start FPS Throughput Estimator\n",
    "fps = FPS().start()\n",
    "\n",
    "# Loop over frames\n",
    "while True:\n",
    "  frame = vs.read()\n",
    "  frame = imutils.resize(frame, width = 600)\n",
    "  (h, w) = frame.shape[:2]\n",
    "\n",
    "  imageBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB = False, crop = False)\n",
    "\n",
    "  detector.setInput(imageBlob)\n",
    "  detections = detector.forward()\n",
    "\n",
    "  for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    if (confidence > 0.2):\n",
    "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "      face = frame[startY: endY, startX: endX]\n",
    "      (fH, fW) = face.shape[:2]\n",
    "\n",
    "      if ((fW < 20) or (fH < 20)):\n",
    "        continue\n",
    "      \n",
    "      faceBlob = cv2.dnn.blobFromImage(face, 1.0/255, (96, 96), (0, 0, 0), swapRB = True, crop = False)\n",
    "\n",
    "      embedder.setInput(faceBlob)\n",
    "      vec = embedder.forward()\n",
    "\n",
    "      preds = recognizer.predict_proba(vec)[0]\n",
    "      j = np.argmax(preds)\n",
    "      proba = preds[j]\n",
    "      name = le.classes_[j]\n",
    "\n",
    "      text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
    "      y = startY - 10 if (startY - 10 > 10) else (startY + 10)\n",
    "\n",
    "      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "      cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "  \n",
    "  fps.update()\n",
    "  cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "  key = cv2.waitKey(1) & 0xFF\n",
    "  if (key == ord('q') or key == ord('Q')):\n",
    "    break\n",
    "  \n",
    "fps.stop()\n",
    "\n",
    "print(\"Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"Approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBWF79rjrRoD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Human PokeDex.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
