{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using CapsNet for Video Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize labels\n",
    "LABELS = set([\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"])\n",
    "\n",
    "# Initialize the list of images\n",
    "print(\"Loading images:\")\n",
    "imagePaths = list(paths.list_images(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Datasets'))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    if label not in LABELS:\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "np.array(labels)\n",
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)\n",
    "\n",
    "# Initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(rotation_range=30, \n",
    "                              zoom_range=0.15, \n",
    "                              width_shift_range=0.2, \n",
    "                              height_shift_range=0.2, \n",
    "                              shear_range=0.15, \n",
    "                              horizontal_flip=True, \n",
    "                              fill_mode=\"nearest\")\n",
    "\n",
    "# Initialize the validation/testing data augmentation object \n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# Define the ImageNet mean subtraction (in RGB order) \n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape = [None, 224, 224, 3], dtype = tf.float32, name = \"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first layer will be composed of 256 maps of 104 x 104 capsules each.\n",
    "Each capsule will output a 128 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_n_maps = 256\n",
    "caps1_n_caps = caps1_n_maps * 104 * 104                                              # 2768896 capsules\n",
    "caps1_n_dims = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.Conv2D(X, name = \"conv1\", \n",
    "                        filters = 4096, \n",
    "                        kernel_size = 9,\n",
    "                        strides = 1,\n",
    "                        padding = \"valid\",\n",
    "                        activation = tf.nn.relu)\n",
    "\n",
    "conv2 = tf.layers.Conv2D(conv1, name = \"conv2\",\n",
    "                        filters = caps1_n_maps * caps1_n_dims, \n",
    "                        kernel_size = 9, \n",
    "                        strides = 2,\n",
    "                        padding = \"valid\",\n",
    "                        activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the kernel size is 9, the image is shrunk by (9 - 1 = 8) pixels after each Conv2D layer.\n",
    "\n",
    "Hence, after two convolution layers we have (224, 224, 3) -> (216, 216, 3) -> (208, 208, 3).\\\n",
    "Moreover, as stride = 2, (208, 208, 3) -> (104, 104, 3)\n",
    "\n",
    "### Output of the Conv2D layer:\n",
    "\n",
    "Number of maps (256) * Vector dimensions per capsule (128) = 32768 feature maps for each capsule.\\\n",
    "Each feature map is 104 * 104."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims], name = \"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, axis = -1, epsilon = 1e-7, name = None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the first capsule layer\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Digit Capsule Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "\n",
    "from capsnet.two_digit_capsules.capsule_layers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from capsnet.two_digit_capsules.utils import combine_images, plot_log\n",
    "\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (for CapsNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Length(keras.layers.Layer):\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print('Length input_shape:', input_shape)\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class Mask(keras.layers.Layer):\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  \n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  \n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.get_shape().as_list()[1])\n",
    "\n",
    "        masked = keras.backend.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print('Mask input shape:', input_shape)\n",
    "        if type(input_shape[0]) is tuple:\n",
    "            return tuple([None, int(input_shape[0][1]) * int(input_shape[0][2])])\n",
    "        else:  \n",
    "            return tuple([None, int(input_shape[1]) * int(input_shape[2])])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vectors, axis=-1):\n",
    "   \n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + keras.backend.epsilon())\n",
    "    return scale * vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = int(input_shape[1])\n",
    "        self.input_dim_capsule = int(input_shape[2])\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs_expand = tf.expand_dims(inputs, 1)\n",
    "\n",
    "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "        inputs_hat = tf.map_fn(lambda x: keras.backend.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "        b = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "            outputs = squash(keras.backend.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                b += keras.backend.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Primary Capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding, do_reshape=False):\n",
    "    conv = keras.layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                               kernel_regularizer=keras.regularizers.l2(1.e-4))(inputs)\n",
    "    output = keras.layers.BatchNormalization(axis=3)(conv)\n",
    "\n",
    "    if not do_reshape:\n",
    "        conv_shape = output.get_shape()\n",
    "        shape = int(int(conv_shape[1]) * int(conv_shape[2]) * (int(conv_shape[3]) / dim_capsule))\n",
    "        desired_shape = [int(math.sqrt(shape)), int(math.sqrt(shape)), dim_capsule]\n",
    "        outputs = keras.layers.Reshape(target_shape=desired_shape, name='primarycap_reshape_1')(output)\n",
    "\n",
    "        return keras.layers.Lambda(squash, name='primarycap_squash_1')(outputs)\n",
    "\n",
    "    conv_shape = output.get_shape()\n",
    "    desired_shape = [int(int(conv_shape[1]) * int(conv_shape[2]) * (int(conv_shape[3]) / dim_capsule)), dim_capsule]\n",
    "    outputs = keras.layers.Reshape(target_shape=desired_shape, name='primarycap_reshape_2')(output)\n",
    "    \n",
    "    return keras.layers.Lambda(squash, name='primarycap_squash_2')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings, primary_capsules=16, number_of_primary_channels=32, digit_capsules=16):\n",
    "    \n",
    "    x = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = keras.layers.Conv2D(filters=256, kernel_size=5, strides=2, padding='valid', name='conv1', kernel_regularizer=keras.regularizers.l2(1.e-4))(x)\n",
    "    norm = keras.layers.BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = keras.layers.Activation('relu')(norm)\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=32, n_channels=16, kernel_size=5, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(primarycaps, dim_capsule=32, n_channels=16, kernel_size=5, strides=2, padding='valid', do_reshape=True)\n",
    "\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=digit_capsules, routings=routings, name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Layer 4: To replace capsule layer with it's length (Not required with TensorFlow)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    # Decoder network\n",
    "    y = keras.layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = keras.models.Sequential(name='decoder')\n",
    "    decoder.add(keras.layers.Dense(1024, activation='relu', input_dim=digit_capsules*n_class))\n",
    "    decoder.add(keras.layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(keras.layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(keras.layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = keras.models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = keras.models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # Manipulate model\n",
    "    noise = keras.layers.Input(shape=(n_class, digit_capsules))\n",
    "    noised_digitcaps = keras.layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = keras.models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "   \n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, save_dir, batch_size, debug, learning_rate, lr_decay, lam_recon):\n",
    "\n",
    "    # Setup callbacks\n",
    "    log = keras.callbacks.CSVLogger(save_dir + '/log.csv')\n",
    "    tb = keras.callbacks.TensorBoard(log_dir=save_dir + '/tensorboard-logs',\n",
    "                                     batch_size=batch_size, histogram_freq=int(debug))\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
    "                                                 save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    lr_decay = keras.callbacks.LearningRateScheduler(schedule=lambda epoch: lr * (lr_decay ** epoch))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., lam_recon],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    # Training\n",
    "    model.fit_generator(generator=cifar10.get_train_generator_for_capsnet(batch_size),\n",
    "                        steps_per_epoch=int(cifar10.TRAIN_SIZE / batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=cifar10.get_validation_data_for_capsnet(),\n",
    "                        callbacks=[log, tb, checkpoint, lr_decay])\n",
    "\n",
    "    model.save_weights(save_dir + '/trained_model.h5')\n",
    "    print('Trained model saved to \\'%s/trained_model.h5\\'' % save_dir)\n",
    "\n",
    "    plot_log(save_dir + '/log.csv', show=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, save_dir):\n",
    "    x_test, y_test = cifar10.get_test_data()\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-'*30 + 'Begin: test' + '-'*30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_latent(model, digit, save_dir):\n",
    "    print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "    x_test, y_test = cifar10.get_test_data()\n",
    "    index = np.argmax(y_test, 1) == args.digit\n",
    "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
    "    x, y = x_test[index][number], y_test[index][number]\n",
    "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
    "    noise = np.zeros([1, 10, 16])\n",
    "    x_recons = []\n",
    "    for dim in range(16):\n",
    "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "            tmp = np.copy(noise)\n",
    "            tmp[:,:,dim] = r\n",
    "            x_recon = model.predict([x, y, tmp])\n",
    "            x_recons.append(x_recon)\n",
    "\n",
    "    x_recons = np.concatenate(x_recons)\n",
    "\n",
    "    img = combine_images(x_recons, height = 16)\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(save_dir + '/manipulate-%d.png' % digit)\n",
    "    print('manipulated result saved to %s/manipulate-%d.png' % (save_dir, digit))\n",
    "    print('-' * 30 + 'End: manipulate' + '-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape= # dataset shape,\n",
    "                                              n_class= # classes,\n",
    "                                              routings=args.routings,\n",
    "                                              primary_capsules=args.primary_capsules,\n",
    "                                              number_of_primary_channels=args.number_of_primary_channels,\n",
    "                                              digit_capsules=args.digit_capsules)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train or test\n",
    "if args.weights is not None:  \n",
    "    model.load_weights(args.weights)\n",
    "if not args.testing:\n",
    "    train(model=model, save_dir, batch_size, debug, learning_rate, lr_decay, lam_recon)\n",
    "else:  \n",
    "    if args.weights is None:\n",
    "        print('No weights are provided. Will test using random initialized weights.')\n",
    "    manipulate_latent(manipulate_model, args)\n",
    "    test(model=eval_model, save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
