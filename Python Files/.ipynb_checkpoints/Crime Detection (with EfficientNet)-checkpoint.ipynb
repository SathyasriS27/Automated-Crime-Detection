{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the set of labels from the spots activity dataset we are\n",
    "# going to train our network on\n",
    "LABELS = set([\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"])\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Datasets'))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# if the label of the current image is not part of of the labels\n",
    "\t# are interested in, then ignore the image\n",
    "\tif label not in LABELS:\n",
    "\t\tcontinue\n",
    "\t# load the image, convert it to RGB channel ordering, and resize\n",
    "\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, stratify=labels, random_state=42)\n",
    "\n",
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=30,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Additional part starts here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "variable_scope module_2/ was unused but the corresponding name_scope was already taken.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eeeb17b9a4a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mefficientnet_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://tfhub.dev/google/efficientnet/b4/classification/1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mloading_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mefficientnet_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# load_model will only have the middle layers of the entire network.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# To use this imported network properly you'll first have to connect your own input layer and output layers like below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[0;32m    163\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such graph variant: tags=%r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m     \u001b[0mabs_state_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_get_state_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m_try_get_state_scope\u001b[1;34m(name, mark_name_scope_used)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0munique_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0munique_name_scope\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m       raise RuntimeError(\n\u001b[0m\u001b[0;32m    402\u001b[0m           \u001b[1;34m\"variable_scope %s was unused but the corresponding \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m           \"name_scope was already taken.\" % abs_state_scope)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: variable_scope module_2/ was unused but the corresponding name_scope was already taken."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfcompatv1\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tfcompatv1.disable_eager_execution()\n",
    "efficientnet_url = \"https://tfhub.dev/google/efficientnet/b4/classification/1\"\n",
    "\n",
    "loading_model = hub.Module(efficientnet_url, trainable = True)\n",
    "# load_model will only have the middle layers of the entire network.\n",
    "# To use this imported network properly you'll first have to connect your own input layer and output layers like below.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = (224, 224, 3)),\n",
    "    loading_model, # The core part of the network, which we imported above\n",
    "    # From below, we add additional layers to make our output better\n",
    "    tf.keras.layers.AveragePooling2D(pool_size = (7, 7)),\n",
    "    tf.keras.layers.Flatten(name = \"flatten\"),\n",
    "    tf.keras.layers.Dense(512, activation = \"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(lb.classes_), activation = \"softmax\")\n",
    "])\n",
    "\n",
    "# Now that the model's architecture has been created, freeze it \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# ------------------------- Training the model -------------------------\n",
    "# Compile the model (Can be done only after you freeze the model)\n",
    "# This is an optimizer similar to SGD that's there in the below code block\n",
    "adam = tf.keras.optimizers.Adam(lr = 1e-4, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7)\n",
    "model.compile(loss = \"categorical_crossentropy\", \n",
    "              optimizer = adam, \n",
    "              metrics = [accuracy, \n",
    "                         tf.keras.metrics.CategoricalAccuracy(), \n",
    "                         tf.keras.metrics.TopKCategoricalAccuracy(),\n",
    "                         tf.keras.metrics.Precision(), \n",
    "                         tf.keras.metrics.Recall(), \n",
    "                         tf.keras.metrics.TruePositives(), \n",
    "                         tf.keras.metrics.TrueNegatives(), \n",
    "                         tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x = trainAug.flow(trainX, trainY, batch_size=32),\n",
    "        steps_per_epoch = len(trainX) // 32,\n",
    "        validation_data = valAug.flow(testX, testY),\n",
    "        validation_steps = len(testX) // 32,\n",
    "        epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Additional part ends here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model...\n",
      "[INFO] Training head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Umale\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "205/205 [==============================] - 119s 512ms/step - loss: 1.4309 - accuracy: 0.5046 - val_loss: 0.8264 - val_accuracy: 0.6967\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 104s 507ms/step - loss: 0.8809 - accuracy: 0.6794 - val_loss: 0.6620 - val_accuracy: 0.7661\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 103s 503ms/step - loss: 0.7386 - accuracy: 0.7386 - val_loss: 0.5724 - val_accuracy: 0.8024\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 105s 513ms/step - loss: 0.6517 - accuracy: 0.7697 - val_loss: 0.5136 - val_accuracy: 0.8235\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 105s 512ms/step - loss: 0.6065 - accuracy: 0.7881 - val_loss: 0.4645 - val_accuracy: 0.8488\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 99s 482ms/step - loss: 0.5663 - accuracy: 0.8064 - val_loss: 0.4281 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 105s 514ms/step - loss: 0.5138 - accuracy: 0.8247 - val_loss: 0.3957 - val_accuracy: 0.8709\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 100s 489ms/step - loss: 0.4898 - accuracy: 0.8334 - val_loss: 0.3753 - val_accuracy: 0.8745\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 103s 504ms/step - loss: 0.4640 - accuracy: 0.8438 - val_loss: 0.3501 - val_accuracy: 0.8865\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 102s 498ms/step - loss: 0.4378 - accuracy: 0.8569 - val_loss: 0.3289 - val_accuracy: 0.8920\n",
      "Epoch 11/50\n",
      "205/205 [==============================] - 101s 491ms/step - loss: 0.4192 - accuracy: 0.8630 - val_loss: 0.3122 - val_accuracy: 0.8994\n",
      "Epoch 12/50\n",
      "205/205 [==============================] - 103s 501ms/step - loss: 0.3885 - accuracy: 0.8729 - val_loss: 0.2971 - val_accuracy: 0.9053\n",
      "Epoch 13/50\n",
      "205/205 [==============================] - 98s 477ms/step - loss: 0.3868 - accuracy: 0.8705 - val_loss: 0.2827 - val_accuracy: 0.9127\n",
      "Epoch 14/50\n",
      "205/205 [==============================] - 95s 463ms/step - loss: 0.3691 - accuracy: 0.8786 - val_loss: 0.2724 - val_accuracy: 0.9164\n",
      "Epoch 15/50\n",
      "205/205 [==============================] - 97s 474ms/step - loss: 0.3486 - accuracy: 0.8911 - val_loss: 0.2612 - val_accuracy: 0.9187\n",
      "Epoch 16/50\n",
      "205/205 [==============================] - 100s 487ms/step - loss: 0.3307 - accuracy: 0.8911 - val_loss: 0.2507 - val_accuracy: 0.9223\n",
      "Epoch 17/50\n",
      "205/205 [==============================] - 156s 761ms/step - loss: 0.3235 - accuracy: 0.8943 - val_loss: 0.2408 - val_accuracy: 0.9278\n",
      "Epoch 18/50\n",
      "205/205 [==============================] - 161s 786ms/step - loss: 0.3262 - accuracy: 0.8951 - val_loss: 0.2340 - val_accuracy: 0.9301\n",
      "Epoch 19/50\n",
      "205/205 [==============================] - 99s 481ms/step - loss: 0.3057 - accuracy: 0.9048 - val_loss: 0.2235 - val_accuracy: 0.9334\n",
      "Epoch 20/50\n",
      "205/205 [==============================] - 105s 512ms/step - loss: 0.2964 - accuracy: 0.9063 - val_loss: 0.2171 - val_accuracy: 0.9352\n",
      "Epoch 21/50\n",
      "205/205 [==============================] - 103s 501ms/step - loss: 0.2878 - accuracy: 0.9048 - val_loss: 0.2099 - val_accuracy: 0.9370\n",
      "Epoch 22/50\n",
      "205/205 [==============================] - 98s 477ms/step - loss: 0.2806 - accuracy: 0.9138 - val_loss: 0.2055 - val_accuracy: 0.9403\n",
      "Epoch 23/50\n",
      "205/205 [==============================] - 102s 496ms/step - loss: 0.2720 - accuracy: 0.9149 - val_loss: 0.1962 - val_accuracy: 0.9430\n",
      "Epoch 24/50\n",
      "205/205 [==============================] - 100s 488ms/step - loss: 0.2666 - accuracy: 0.9211 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
      "Epoch 25/50\n",
      "205/205 [==============================] - 102s 499ms/step - loss: 0.2665 - accuracy: 0.9140 - val_loss: 0.1868 - val_accuracy: 0.9467\n",
      "Epoch 26/50\n",
      "205/205 [==============================] - 105s 514ms/step - loss: 0.2576 - accuracy: 0.9202 - val_loss: 0.1844 - val_accuracy: 0.9485\n",
      "Epoch 27/50\n",
      "205/205 [==============================] - 103s 502ms/step - loss: 0.2503 - accuracy: 0.9230 - val_loss: 0.1782 - val_accuracy: 0.9490\n",
      "Epoch 28/50\n",
      "205/205 [==============================] - 107s 521ms/step - loss: 0.2493 - accuracy: 0.9233 - val_loss: 0.1754 - val_accuracy: 0.9481\n",
      "Epoch 29/50\n",
      "205/205 [==============================] - 103s 501ms/step - loss: 0.2370 - accuracy: 0.9297 - val_loss: 0.1696 - val_accuracy: 0.9513\n",
      "Epoch 30/50\n",
      "205/205 [==============================] - 103s 504ms/step - loss: 0.2287 - accuracy: 0.9294 - val_loss: 0.1674 - val_accuracy: 0.9513\n",
      "Epoch 31/50\n",
      "205/205 [==============================] - 101s 495ms/step - loss: 0.2197 - accuracy: 0.9338 - val_loss: 0.1609 - val_accuracy: 0.9536\n",
      "Epoch 32/50\n",
      "205/205 [==============================] - 102s 498ms/step - loss: 0.2186 - accuracy: 0.9309 - val_loss: 0.1618 - val_accuracy: 0.9504\n",
      "Epoch 33/50\n",
      "205/205 [==============================] - 100s 489ms/step - loss: 0.2175 - accuracy: 0.9326 - val_loss: 0.1575 - val_accuracy: 0.9517\n",
      "Epoch 34/50\n",
      "205/205 [==============================] - 104s 509ms/step - loss: 0.2139 - accuracy: 0.9352 - val_loss: 0.1555 - val_accuracy: 0.9522\n",
      "Epoch 35/50\n",
      "205/205 [==============================] - 105s 514ms/step - loss: 0.2140 - accuracy: 0.9343 - val_loss: 0.1555 - val_accuracy: 0.9522\n",
      "Epoch 36/50\n",
      "205/205 [==============================] - 101s 493ms/step - loss: 0.2094 - accuracy: 0.9381 - val_loss: 0.1486 - val_accuracy: 0.9545\n",
      "Epoch 37/50\n",
      "205/205 [==============================] - 103s 502ms/step - loss: 0.2040 - accuracy: 0.9381 - val_loss: 0.1426 - val_accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "205/205 [==============================] - 101s 495ms/step - loss: 0.2026 - accuracy: 0.9372 - val_loss: 0.1437 - val_accuracy: 0.9586\n",
      "Epoch 39/50\n",
      "205/205 [==============================] - 100s 487ms/step - loss: 0.1948 - accuracy: 0.9426 - val_loss: 0.1403 - val_accuracy: 0.9586\n",
      "Epoch 40/50\n",
      "205/205 [==============================] - 97s 474ms/step - loss: 0.1907 - accuracy: 0.9446 - val_loss: 0.1378 - val_accuracy: 0.9609\n",
      "Epoch 41/50\n",
      "205/205 [==============================] - 97s 475ms/step - loss: 0.1923 - accuracy: 0.9426 - val_loss: 0.1355 - val_accuracy: 0.9582\n",
      "Epoch 42/50\n",
      "205/205 [==============================] - 98s 479ms/step - loss: 0.1822 - accuracy: 0.9443 - val_loss: 0.1340 - val_accuracy: 0.9609\n",
      "Epoch 43/50\n",
      "205/205 [==============================] - 94s 459ms/step - loss: 0.1881 - accuracy: 0.9422 - val_loss: 0.1311 - val_accuracy: 0.9609\n",
      "Epoch 44/50\n",
      "205/205 [==============================] - 97s 471ms/step - loss: 0.1779 - accuracy: 0.9497 - val_loss: 0.1266 - val_accuracy: 0.9623\n",
      "Epoch 45/50\n",
      "205/205 [==============================] - 97s 475ms/step - loss: 0.1821 - accuracy: 0.9469 - val_loss: 0.1257 - val_accuracy: 0.9646\n",
      "Epoch 46/50\n",
      "205/205 [==============================] - 98s 476ms/step - loss: 0.1722 - accuracy: 0.9484 - val_loss: 0.1233 - val_accuracy: 0.9651\n",
      "Epoch 47/50\n",
      "205/205 [==============================] - 97s 473ms/step - loss: 0.1741 - accuracy: 0.9486 - val_loss: 0.1224 - val_accuracy: 0.9646\n",
      "Epoch 48/50\n",
      "205/205 [==============================] - 101s 494ms/step - loss: 0.1669 - accuracy: 0.9503 - val_loss: 0.1207 - val_accuracy: 0.9665\n",
      "Epoch 49/50\n",
      "205/205 [==============================] - 105s 514ms/step - loss: 0.1677 - accuracy: 0.9500 - val_loss: 0.1179 - val_accuracy: 0.9678\n",
      "Epoch 50/50\n",
      "205/205 [==============================] - 181s 886ms/step - loss: 0.1581 - accuracy: 0.9535 - val_loss: 0.1168 - val_accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "with tf.device('/gpu:0'):\n",
    "    # load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "    # off\n",
    "    baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "    # construct the head of the model that will be placed on top of the\n",
    "    # the base model\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "\n",
    "    # place the head FC model on top of the base model (this will become\n",
    "    # the actual model we will train)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "    # loop over all layers in the base model and freeze them so they will\n",
    "    # *not* be updated during the training process\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile our model (this needs to be done after our setting our\n",
    "    # layers to being non-trainable)\n",
    "    print(\"[INFO] Compiling model...\")\n",
    "    opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / n_epochs)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    # train the head of the network for a few epochs (all other layers\n",
    "    # are frozen) -- this will allow the new FC layers to start to become\n",
    "    # initialized with actual \"learned\" values versus pure random\n",
    "    print(\"[INFO] Training head...\")\n",
    "    H = model.fit(\n",
    "        x=trainAug.flow(trainX, trainY, batch_size=32),\n",
    "        steps_per_epoch=len(trainX) // 32,\n",
    "        validation_data=valAug.flow(testX, testY),\n",
    "        validation_steps=len(testX) // 32,\n",
    "        epochs=n_epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Abuse       0.96      0.93      0.95       234\n",
      "     Assault       0.94      0.51      0.66        57\n",
      "    Fighting       0.91      0.96      0.93       393\n",
      "      Normal       1.00      1.00      1.00      1008\n",
      "     Robbery       0.95      0.98      0.96       333\n",
      "   Vandalism       0.97      1.00      0.98       172\n",
      "\n",
      "    accuracy                           0.97      2197\n",
      "   macro avg       0.95      0.90      0.91      2197\n",
      "weighted avg       0.97      0.97      0.97      2197\n",
      "\n",
      "[INFO] Serializing network...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5992e95c89d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] Serializing network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmodelPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# serialize the label binarizer to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2109\u001b[0m     \"\"\"\n\u001b[0;32m   2110\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2111\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   2112\u001b[0m                     signatures, options, save_traces)\n\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    144\u001b[0m           \u001b[1;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m--> 146\u001b[1;33m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[0;32m    147\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    148\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX.astype(\"float32\"), batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = n_epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plotPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Plots'\n",
    "plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Serializing network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Umale\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] Serializing network...\")\n",
    "modelPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\trained_crime'\n",
    "model.save(modelPath, save_format=\"h5\")\n",
    "\n",
    "# serialize the label binarizer to disk\n",
    "lbPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\lb.pickle'\n",
    "f = open(lbPath, \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Video Classification with Rolling Prediction Averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# load the trained model and label binarizer from disk\n",
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "lbPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\lb.pickle'\n",
    "modelPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\trained_crime'\n",
    "\n",
    "model = load_model(modelPath)\n",
    "lb = pickle.loads(open(lbPath, \"rb\").read())\n",
    "\n",
    "# initialize the image mean for mean subtraction along with the\n",
    "# predictions queue\n",
    "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "Q = deque(maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cleaning up...\n",
      "Elapsed time: 173.63\n",
      "Approx. FPS: 4.40\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream, pointer to output video file, and\n",
    "# frame dimensions\n",
    "vs = VideoStream(src = 0).start()\n",
    "writer = None\n",
    "(W, H) = (None, None)\n",
    "\n",
    "# Change this for different cameras\n",
    "cameraNo = \"A Block\" \n",
    "\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "fps = FPS().start()\n",
    "\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "\t# read the next frame from the file\n",
    "\t# (grabbed, frame) = vs.read()\n",
    "    frame = vs.read()\n",
    "    \n",
    "\t# if the frame was not grabbed, then we have reached the end\n",
    "\t# of the stream\n",
    "\t# if not grabbed:\n",
    "\t# \tbreak\n",
    "        \n",
    "\t# if the frame dimensions are empty, grab them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "        \n",
    "    # clone the output frame, then convert it from BGR to RGB\n",
    "\t# ordering, resize the frame to a fixed 224x224, and then\n",
    "\t# perform mean subtraction\n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    \n",
    "    # make predictions on the frame and then update the predictions\n",
    "\t# queue\n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Q.append(preds)\n",
    "    \n",
    "\t# perform prediction averaging over the current history of\n",
    "\t# previous predictions\n",
    "    results = np.array(Q).mean(axis=0)\n",
    "    i = np.argmax(results)\n",
    "    label = lb.classes_[i]\n",
    "    \n",
    "    text = \"activity: {}\".format(label)\n",
    "    cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\n",
    "\t# check if the video writer is None\n",
    "    outPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Output'\n",
    "    if writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(outPath, fourcc, 30, (W, H), True)\n",
    "        \n",
    "\t# write the output frame to disk\n",
    "    cv2.imshow(\"Frame\", output)\n",
    "    \n",
    "\t# show the output image\n",
    "    fps.update()\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "    if (key == ord(\"q\") or key == ord('Q')):\n",
    "        break\n",
    "\n",
    "# release the file pointers\n",
    "print(\"[INFO] Cleaning up...\")\n",
    "fps.stop()\n",
    "print(\"Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"Approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "writer.release()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(src = 0).start()\n",
    "writer = None\n",
    "(W, H) = (None, None)\n",
    "cameraNo = \"A Block\" \n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "fps = FPS().start()\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "        \n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    \n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Q.append(preds)\n",
    "    \n",
    "    results = np.array(Q).mean(axis=0)\n",
    "    i = np.argmax(results)\n",
    "    label = lb.classes_[i]\n",
    "    cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\n",
    "    outPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Output'\n",
    "    if writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(outPath, fourcc, 30, (W, H), True)\n",
    "        \n",
    "    cv2.imshow(\"Frame\", output)\n",
    "    fps.update()\n",
    "\n",
    "fps.stop()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
