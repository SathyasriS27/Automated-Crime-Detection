{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human PokeDex Playground.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/newb-dev-1008/Human-PokeDex/blob/master/Human_PokeDex_Playground.ipynb",
      "authorship_tag": "ABX9TyM2Ew+c9XJIgH7jTRzjjL7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newb-dev-1008/Human-PokeDex/blob/master/Human_PokeDex_Playground_with_Firebase_Storage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHu1mDcHAcPU"
      },
      "source": [
        "# **Human PokeDex - Playground Notebook**\n",
        "\n",
        "This notebook will be used for trying parts of the software to test their implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rgxQ9qbApnx"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3V9fH4sBNXr"
      },
      "source": [
        "## **Functions for augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-MlaMMJGyvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e249d90-d3d1-44bb-a899-1ad621301654"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/79/861f38d5830cff631e30e33b127076bfef8ac98171e51daa06df0118c75f/Augmentor-0.2.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (4.41.1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (1.19.5)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U795lUjnHr2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc6223b-6424-4348-b032-ef420798f390"
      },
      "source": [
        "!pip install --upgrade imutils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV7B9ibC0-yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db31b8c-d94b-4a25-ecc3-5e19825cd48c"
      },
      "source": [
        "!pip install pyrebase"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyrebase\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/1f/86ec68bfe0d6ffeadbab2ab0651ddf1c7206a0c4421b39baeb69b3a9c5cd/Pyrebase-3.0.27-py3-none-any.whl\n",
            "Collecting requests-toolbelt==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/60/cc85ca45c85585191e70e21687aeaa74ec4e555a1404628ba77b8af7d92e/requests_toolbelt-0.7.0-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hCollecting pycryptodome==3.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ef/4514a01be3d8f5383cd12fc5612ffd8a2508ac7e7ff6bde2da708e71c9a3/pycryptodome-3.4.3.tar.gz (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 13.1MB/s \n",
            "\u001b[?25hCollecting oauth2client==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.5MB/s \n",
            "\u001b[?25hCollecting requests==2.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/03/92d3278bf8287c5caa07dbd9ea139027d5a3592b0f4d14abf072f890fab2/requests-2.11.1-py2.py3-none-any.whl (514kB)\n",
            "\u001b[K     |████████████████████████████████| 522kB 38.9MB/s \n",
            "\u001b[?25hCollecting python-jwt==2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/2a/9c4230b09f63737e7beb34e3a19895cd50c5ff88af16d3cd54cd71e2325a/python_jwt-2.0.1-py2.py3-none-any.whl\n",
            "Collecting gcloud==0.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/9d/56ecba02b4c117a43a906098095bccaea94d3edf57cb407c071efd87002f/gcloud-0.17.0.tar.gz (458kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (4.7.2)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (1.15.0)\n",
            "Collecting jws>=0.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/01/9e/1536d578ed50f5fe8196310ddcc921a3cd8e973312d60ac74488b805d395/jws-0.1.3.tar.gz\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud==0.17.0->pyrebase) (56.0.0)\n",
            "Building wheels for collected packages: pycryptodome, oauth2client, gcloud, jws\n",
            "  Building wheel for pycryptodome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycryptodome: filename=pycryptodome-3.4.3-cp37-cp37m-linux_x86_64.whl size=6813257 sha256=bde181671e8e3c6f09848116235853a1e6aefe00ad5a34055f47050a73e00b88\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/9d/63/f6aea5612d1682a50b25857b0358e2ecec878a0bc42ba3af4c\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oauth2client: filename=oauth2client-3.0.0-cp37-none-any.whl size=106383 sha256=5ffa2a1e4565da93b12e43ce5627c8de2764cc176492676735f054c2ab3aa7f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.17.0-cp37-none-any.whl size=638015 sha256=f4ce91e62a4da3584ae4b7b09122d11fee1cdb3bc2d05ae40ba8b029bd268fa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/04/ff/66c87c7e2419fd477f52015468ec5301d9480b6f3896babda4\n",
            "  Building wheel for jws (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jws: filename=jws-0.1.3-cp37-none-any.whl size=9411 sha256=613c74c6642dc9df030946acecb3dd4c9b70c73d792a723a361631e644652fd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/66/97/11aed97607cb2379c1d35d02bdc159bcc3918eb0cc20f7eb9a\n",
            "Successfully built pycryptodome oauth2client gcloud jws\n",
            "\u001b[31mERROR: tensorflow-datasets 4.0.1 has requirement requests>=2.19.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.4.1 has requirement requests<3,>=2.21.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement requests<3.0.0,>=2.13.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-datareader 0.9.0 has requirement requests>=2.19.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement requests<3.0.0dev,>=2.18.0, but you'll have requests 2.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, requests-toolbelt, pycryptodome, oauth2client, jws, python-jwt, gcloud, pyrebase\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "Successfully installed gcloud-0.17.0 jws-0.1.3 oauth2client-3.0.0 pycryptodome-3.4.3 pyrebase-3.0.27 python-jwt-2.0.1 requests-2.11.1 requests-toolbelt-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS3sVzOk6DTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18535937-9caa-481c-adae-104ea9c4ea2a"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khtxk9lCwvpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7128ebd9-e358-4ca9-db37-775ce6ef1823"
      },
      "source": [
        "!pip install --upgrade firebase-admin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting firebase-admin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/6d/5232504010e949d8ed52405906f2c7b5b68d04993fe33fa0d79c1849209b/firebase_admin-5.0.0-py3-none-any.whl (113kB)\n",
            "\r\u001b[K     |███                             | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 30kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 40kB 23.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 51kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 61kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 71kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 81kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 102kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 17.6MB/s \n",
            "\u001b[?25hCollecting google-cloud-storage>=1.37.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/75/78ed0d1ef691592b94e7a3d9f58153298166486342a97df82d3c5b66cc16/google_cloud_storage-1.38.0-py2.py3-none-any.whl (103kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51kB 30.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 32.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81kB 29.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 92kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102kB 30.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-python-client>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.12.8)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: cachecontrol>=0.12.6 in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (0.12.6)\n",
            "Collecting google-cloud-firestore>=2.1.0; platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/2d/4e756a38791ba6bc38949ebb2a1b6d989ee7a8392155ec0c5b5ef9d0e338/google_cloud_firestore-2.1.0-py2.py3-none-any.whl (209kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 42.3MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/fc/6e8c449185cb8862af353c1164100ff75e32d55ba1de3baf9eaa01b7d2a9/google_cloud_core-1.6.0-py2.py3-none-any.whl\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth<2.0dev,>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (1.28.1)\n",
            "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/52/4b086e0d15245b648e2b6d408fb2f2974a3a5a405de5d7fae25cd085a3fa/google_resumable_media-1.2.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.0.4)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (1.0.2)\n",
            "Collecting proto-plus>=1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/8a/61c5a9b9b6288f9b060b6e3d88374fc083953a29aeac7206616c2d3c9c8e/proto_plus-1.18.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.37.1->firebase-admin) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.37.1->firebase-admin) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.37.1->firebase-admin) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.37.1->firebase-admin) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.37.1->firebase-admin) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.37.1->firebase-admin) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.37.1->firebase-admin) (0.2.8)\n",
            "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/ae/b6efa1019e18c6c791f0f5cd93b2ff40f8f06696dbf04db39ec0f5591b1e/google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.37.1->firebase-admin) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.37.1->firebase-admin) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.37.1->firebase-admin) (2.20)\n",
            "\u001b[31mERROR: pyrebase 3.0.27 has requirement requests==2.11.1, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-bigquery 1.21.0 has requirement google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-cloud-core, requests, google-crc32c, google-resumable-media, google-cloud-storage, proto-plus, google-cloud-firestore, firebase-admin\n",
            "  Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Found existing installation: requests 2.11.1\n",
            "    Uninstalling requests-2.11.1:\n",
            "      Successfully uninstalled requests-2.11.1\n",
            "  Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Found existing installation: google-cloud-firestore 1.7.0\n",
            "    Uninstalling google-cloud-firestore-1.7.0:\n",
            "      Successfully uninstalled google-cloud-firestore-1.7.0\n",
            "  Found existing installation: firebase-admin 4.4.0\n",
            "    Uninstalling firebase-admin-4.4.0:\n",
            "      Successfully uninstalled firebase-admin-4.4.0\n",
            "Successfully installed firebase-admin-5.0.0 google-cloud-core-1.6.0 google-cloud-firestore-2.1.0 google-cloud-storage-1.38.0 google-crc32c-1.1.2 google-resumable-media-1.2.0 proto-plus-1.18.1 requests-2.25.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJDEv1J3Bc1o"
      },
      "source": [
        "import numpy as np\n",
        "from imutils import paths as pts\n",
        "import Augmentor\n",
        "import cv2\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import firestore\n",
        "from firebase_admin import credentials\n",
        "from skimage import io\n",
        "import gdown\n",
        "import requests\n",
        "import pyrebase\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "# ----------------------------- Functions -----------------------------\n",
        "\n",
        "# Function to extract path of new datasets uploaded\n",
        "def extractPath(i):\n",
        "  a = (str(i).split(',')[1:])\n",
        "  b = str(a[-1]).rstrip('>')\n",
        "  c = b.lstrip()\n",
        "  return c\n",
        "\n",
        "# Function to retrieve person's name\n",
        "def firestoreName():\n",
        "  users_ref = db.collection(u'New Users')\n",
        "  docs = users_ref.stream()\n",
        "\n",
        "  userName = \"\"\n",
        "\n",
        "  for doc in docs:\n",
        "    dict1 = doc.to_dict()\n",
        "    userName = dict1['Username']\n",
        "  \n",
        "  return userName\n",
        "\n",
        "# Function to blur the image\n",
        "def blurImage(imagePath, userName, i):\n",
        "    old_image = io.imread(imagePath)\n",
        "    # old_image = cv2.imread(imagePath)\n",
        "    image = old_image.copy()\n",
        "    blurredImage = cv2.blur(image, (3, 3))\n",
        "    filename = \"blurred_\" + userName + \"_\" + str(i) + \".jpg\"\n",
        "    destination = 'Datasets/' + userName + '/' + filename\n",
        "    # os.chdir(r'/content/drive/MyDrive/Open Lab/Datasets 1/' + userName)\n",
        "    cv2.imwrite(filename, blurredImage) \n",
        "    return destination, filename\n",
        "\n",
        "# Function to sharpen the image\n",
        "def sharpenImage(imagePath, userName, i):\n",
        "    old_image = io.imread(imagePath)\n",
        "    image = old_image.copy()\n",
        "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "    sharpImage = cv2.filter2D(image, -1, kernel)\n",
        "    filename = \"sharpened_\" + userName + \"_\" + str(i) + \".jpg\"\n",
        "    destination = 'Datasets/' + userName + '/' + filename\n",
        "    # os.chdir(r'/content/drive/MyDrive/Open Lab/Datasets 1/' + userName)\n",
        "    cv2.imwrite(filename, sharpImage) \n",
        "    return destination, filename\n",
        "\n",
        "# Function to add Sepia effect \n",
        "def sepiaImage(imagePath, userName, i):\n",
        "    old_image = io.imread(imagePath)\n",
        "    image = old_image.copy()\n",
        "    kernel = np.array([[0.272, 0.534, 0.131], [0.349, 0.686, 0.168], [0.393, 0.769, 0.189]])\n",
        "    sepiaImage = cv2.filter2D(image, -1, kernel)\n",
        "    filename = \"sepia_\" + userName +  \"_\" + str(i) + \".jpg\"\n",
        "    destination = 'Datasets/' + userName + '/' + filename\n",
        "    # os.chdir(r'/content/drive/MyDrive/Open Lab/Datasets 1/' + userName)\n",
        "    cv2.imwrite(filename, sepiaImage) \n",
        "    return destination, filename\n",
        "\n",
        "# Function to add brightness\n",
        "def brightImage(imagePath, userName, i):\n",
        "    old_image = io.imread(imagePath)\n",
        "    image = old_image.copy()\n",
        "    brightImage = cv2.convertScaleAbs(image, 3)\n",
        "    filename = \"bright_\" + userName +  \"_\" + str(i) + \".jpg\"\n",
        "    destination = 'Datasets/' + userName + '/' + filename\n",
        "    cv2.imwrite(filename, brightImage) \n",
        "    return destination, filename\n",
        "\n",
        "# Tilt image to certain angles\n",
        "def tiltedImage(imagePath, userName):\n",
        "    p = Augmentor.Pipeline(imagePath)\n",
        "    p.rotate(1, 15, 15)\n",
        "    old_image = io.imread(imagePath)\n",
        "    \n",
        "# Mirror image\n",
        "def mirrorImage(imagePath, userName):\n",
        "    p = Augmentor.Pipeline(imagePath)\n",
        "    p.flip_left_right(probability = 1)\n",
        "    old_image = io.imread(imagePath)\n",
        "\n",
        "# Shearing image\n",
        "def shearImage(imagePath, userName):\n",
        "    p = Augmentor.Pipeline(imagePath)\n",
        "    p.shear(probability = 1, max_shear_left = 15, max_shear_right = 15)\n",
        "    old_image = io.imread(imagePath)\n",
        "\n",
        "# Skewing image\n",
        "def skewedImage(imagePath, userName):\n",
        "    p = Augmentor.Pipeline(imagePath)\n",
        "    p.skew(probability = 1, magnitude = 0.7)\n",
        "    old_image = io.imread(imagePath)\n",
        "\n",
        "# Black and White \n",
        "def bwImage(imagePath, userName):\n",
        "    p = Augmentor.Pipeline(imagePath)\n",
        "    p.black_and_white(probability = 1, threshold = 255)\n",
        "    old_image = io.imread(imagePath)\n",
        "  \n",
        "# Initialize pipeline\n",
        "def usePipeline(imagePath, destination, userName):\n",
        "    p = Augmentor.Pipeline(imagePath, imagePath)\n",
        "    p1 = Augmentor.Pipeline(imagePath, imagePath)\n",
        "    p2 = Augmentor.Pipeline(imagePath, imagePath)\n",
        "    p3 = Augmentor.Pipeline(imagePath, imagePath)\n",
        "    p4 = Augmentor.Pipeline(imagePath, imagePath)\n",
        "    \n",
        "    p.rotate(1, 15, 15)\n",
        "    p1.flip_left_right(probability = 1)\n",
        "    p2.shear(probability = 1, max_shear_left = 15, max_shear_right = 15)\n",
        "    p3.skew(probability = 1, magnitude = 0.7)\n",
        "    p4.black_and_white(probability = 1, threshold = 64)\n",
        "\n",
        "    p.sample(25)\n",
        "    p1.sample(25)\n",
        "    p2.sample(25)\n",
        "    p3.sample(25)\n",
        "    p4.sample(25)\n",
        "\n",
        "    uploadFiles(imagePath, destination, userName)\n",
        "  \n",
        "# Function to upload files to Firebase Storage\n",
        "def uploadFiles(imagePath, destination, userName):\n",
        "    imagePaths = list(pts.list_images(imagePath))\n",
        "    for imgPath in imagePaths:\n",
        "      fileName = imgPath.split('/')[-1]\n",
        "      dest = destination + \"/\" + fileName\n",
        "      storage.child(dest).put(imgPath)\n",
        "\n",
        "# Function to delete collection\n",
        "def deleteCollection():\n",
        "    users_ref = db.collection(u'New Users')\n",
        "    docs = users_ref.stream()\n",
        "\n",
        "    for doc in docs:\n",
        "      doc.reference.delete()\n",
        "\n",
        "# Function to delete /New Datasets folder from Firebase Storage\n",
        "def deleteFolder(folderPaths):\n",
        "    for folderPath in folderPaths:\n",
        "      storage.delete(folderPath)\n",
        "\n",
        "# Function to create new datasets and store them in Firebase Storage\n",
        "def newDatasets(imagePaths, paths):\n",
        "\n",
        "  name = firestoreName()\n",
        "  count = 0\n",
        "\n",
        "  for imagePath in imagePaths:\n",
        "\n",
        "      # Perform data augmentation\n",
        "      \n",
        "      destbl, filebl = blurImage(imagePath, name, count)\n",
        "      destsh, filesh = sharpenImage(imagePath, name, count)\n",
        "      destse, filese = sepiaImage(imagePath, name, count)\n",
        "      destbr, filebr = brightImage(imagePath, name, count)\n",
        "\n",
        "      storage.child(destbl).put(filebl)\n",
        "      storage.child(destsh).put(filesh)\n",
        "      storage.child(destse).put(filese)\n",
        "      storage.child(destbr).put(filebr)\n",
        "\n",
        "      os.remove(filebl)\n",
        "      os.remove(filesh)\n",
        "      os.remove(filese)\n",
        "      os.remove(filebr)\n",
        "\n",
        "      count += 1\n",
        "\n",
        "  imgPath = str(os.getcwd()) + \"/temp\"\n",
        "\n",
        "  imgPaths = []\n",
        "  for j in paths:\n",
        "    i = str(j)\n",
        "    dest = imgPath + \"/\" + str((i.split('/'))[-1])\n",
        "    storage.child(i).download(dest)\n",
        "    imgPaths.append(dest)\n",
        "\n",
        "  destination = 'Datasets/' + name\n",
        "  usePipeline(imgPath, destination, name)\n",
        "\n",
        "  print(\"\\nDone with all images.\\n\")\n",
        "\n",
        "  # destination1 = '/content/drive/MyDrive/Open Lab/Datasets 1/' + name\n",
        "  # movePhotos(destination1, name)\n",
        "  deleteCollection()\n",
        "  print('\\nDeleted new datasets after moving.\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObdcCk9meJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420c48ec-80c5-461a-ca80-2d732674ba85"
      },
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1vIl_ircPdiLWTkuV2LSTYTJzFOy_cAGB\"\n",
        "r = requests.get(url, allow_redirects = True)\n",
        "# output = 'serviceRequestKey.json'\n",
        "data = r.json()\n",
        "\n",
        "f = open('serviceRequestKey.json', 'w')\n",
        "json.dump(data, f)\n",
        "f.close()\n",
        "\n",
        "config = {\n",
        "    \"apiKey\": \"AIzaSyBqFROlkrLs0fMirkUoV4Sutn8AkTlBPlQ\",\n",
        "    \"authDomain\": \"human-pokedex.firebaseapp.com\",\n",
        "    \"projectId\": \"human-pokedex\",\n",
        "    \"databaseURL\": \"\",\n",
        "    \"storageBucket\": \"human-pokedex.appspot.com\",\n",
        "    \"messagingSenderId\": \"466324270281\",\n",
        "    \"appId\": \"1:466324270281:web:d61e64e5c20932db15b118\",\n",
        "    \"measurementId\": \"G-V0DRGWJ51J\",\n",
        "    \"serviceAccount\": \"serviceRequestKey.json\"\n",
        "}\n",
        "\n",
        "firebase = pyrebase.initialize_app(config)\n",
        "storage = firebase.storage()\n",
        "\n",
        "cred = credentials.Certificate(\"serviceRequestKey.json\")\n",
        "firebase_admin.initialize_app(cred, {'projectId': 'human-pokedex'})\n",
        "db = firestore.client()\n",
        "\n",
        "# List containing paths of images in Firebase Storage (New Datasets/)\n",
        "l = storage.list_files()\n",
        "paths1 = []\n",
        "for i in l:\n",
        "  path = extractPath(i)\n",
        "  if (path.split('/')[0] == \"New Datasets\"):\n",
        "    paths1.append(path)\n",
        "paths2 = paths1[1:]\n",
        "paths2.append(paths2[0])\n",
        "paths2.pop(0)\n",
        "paths1 = paths1[2:]\n",
        "\n",
        "# List of corresponding URLs for all paths in previous list\n",
        "path_urls = []\n",
        "for i in paths1:\n",
        "  url = storage.child(str(i)).get_url(None)\n",
        "  path_urls.append(url)\n",
        "\n",
        "# List containing paths of images in Firebase Storage (Photos/)\n",
        "lx = storage.list_files()\n",
        "paths1x = []\n",
        "for i in lx:\n",
        "  pathx = extractPath(i)\n",
        "  if (pathx.split('/')[0] == \"Photos\"):\n",
        "    paths1x.append(pathx)\n",
        "paths2x = paths1x[1:]\n",
        "paths2x.append(paths2x[0])\n",
        "paths2x.pop(0)\n",
        "paths1x = paths1x[2:]\n",
        "\n",
        "# List of corresponding URLs for all paths in previous list\n",
        "pathx_urls = []\n",
        "for i in paths1x:\n",
        "  urlx = storage.child(str(i)).get_url(None)\n",
        "  pathx_urls.append(urlx)\n",
        "\n",
        "# Added the URLs of photos to Firestore\n",
        "name = firestoreName()\n",
        "db.collection(u'Users').document(u'Username ' + name).update({u'photoStored' : pathx_urls})\n",
        "\n",
        "# Perform Data Augmentation and upload new dataset\n",
        "print(paths1)\n",
        "input(\"Press any key to continue:\\n\")\n",
        "imgPath = str(os.getcwd()) + \"/temp\"\n",
        "os.mkdir(imgPath)\n",
        "newDatasets(path_urls, paths1)\n",
        "shutil.rmtree(imgPath)\n",
        "deleteFolder(paths2)\n",
        "print(\"New Datasets folder deleted.\\n\")\n",
        "# Add a line to save photo folder URL to user's Firestore document"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['New Datasets/IMG-20210308-WA0298.jpg', 'New Datasets/IMG-20210308-WA0299.jpg', 'New Datasets/IMG-20210308-WA0300.jpg', 'New Datasets/IMG-20210308-WA0301.jpg', 'New Datasets/IMG-20210308-WA0303.jpg', 'New Datasets/IMG-20210308-WA0304.jpg', 'New Datasets/IMG-20210308-WA0305.jpg', 'New Datasets/IMG-20210308-WA0306.jpg', 'New Datasets/IMG-20210308-WA0307.jpg', 'New Datasets/IMG-20210308-WA0308.jpg', 'New Datasets/IMG-20210308-WA0309.jpg']\n",
            "Press any key to continue:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rExecuting Pipeline:   0%|          | 0/25 [00:00<?, ? Samples/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initialised with 11 image(s) found.\n",
            "Output directory set to /content/temp.Initialised with 11 image(s) found.\n",
            "Output directory set to /content/temp.Initialised with 11 image(s) found.\n",
            "Output directory set to /content/temp.Initialised with 11 image(s) found.\n",
            "Output directory set to /content/temp.Initialised with 11 image(s) found.\n",
            "Output directory set to /content/temp."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=958x1280 at 0x7F0F2CA7CD10>: 100%|██████████| 25/25 [00:04<00:00,  5.59 Samples/s]\n",
            "Processing <PIL.Image.Image image mode=RGB size=958x1280 at 0x7F0F2CABF990>: 100%|██████████| 25/25 [00:01<00:00, 21.73 Samples/s]\n",
            "Processing <PIL.Image.Image image mode=RGB size=866x1156 at 0x7F0F2A835A90>: 100%|██████████| 25/25 [00:04<00:00,  6.12 Samples/s]\n",
            "Processing <PIL.Image.Image image mode=RGB size=958x1280 at 0x7F0F2A829090>: 100%|██████████| 25/25 [00:03<00:00,  6.61 Samples/s]\n",
            "Processing <PIL.Image.Image image mode=1 size=958x1280 at 0x7F0F2A817AD0>: 100%|██████████| 25/25 [00:00<00:00, 29.57 Samples/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done with all images.\n",
            "\n",
            "\n",
            "Deleted new datasets after moving.\n",
            "\n",
            "New Datasets folder deleted.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5taoRp1qtkzs"
      },
      "source": [
        " ## **Recognising and tracking students on CCTV footage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s066GPKetkL4"
      },
      "source": [
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "import urllib\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LOAIQBgqZSJ"
      },
      "source": [
        "print(\"Loading face detector...\\n\")\n",
        "protoPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Project Files\\opencv-face-recognition\\face_detection_model', 'deploy.prototxt'])\n",
        "modelPath = os.path.sep.join([r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Project Files\\opencv-face-recognition\\face_detection_model', 'res10_300x300_ssd_iter_140000.caffemodel'])\n",
        "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
        "print(\"Loaded face detector.\\n\")\n",
        "\n",
        "# Load our serialized face embedding model\n",
        "print(\"\\nLoading face recognizer...\\n\")\n",
        "embedder = cv2.dnn.readNetFromTorch(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Project Files\\opencv-face-recognition\\openface_nn4.small2.v1.t7')\n",
        "print(\"Loaded Face Recognizer.\\n\")\n",
        "\n",
        "# Load the SVM Model and LabelEncoder\n",
        "recognizer = pickle.loads(open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Project Files\\Trained Models\\recognizer.pickle', \"rb\").read())\n",
        "le = pickle.loads(open(r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Project Files\\Trained Models\\le.pickle', \"rb\").read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW-4gAllu4Iw"
      },
      "source": [
        "# Running video from custom camera/ video source over seperate IP Address\n",
        "\n",
        "print(\"Starting video stream:\")\n",
        "\n",
        "# vs = VideoStream(src = 0).start()\n",
        "url = \"https://192.168.1.6:8080/shot.jpg\"\n",
        "\n",
        "while True:\n",
        "  imgResp = urllib.request.urlopen(url)\n",
        "  imgNp = np.array(bytearray(imgResp.read()), dtype = np.uint8)\n",
        "  img = cv2.imdecode(imgNp, cv2.IMREAD_COLOR)\n",
        "  # cv2.imshow('test', img)\n",
        "\n",
        "  img = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104, 177, 123), swapRB = False, crop = False)\n",
        "\n",
        "  detector = setInput(imageBlob)\n",
        "  detections = detector.forward()\n",
        "\n",
        "  # loop over the detections\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    # extract the confidence (i.e., probability) associated with the prediction\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    # filter out weak detections\n",
        "\n",
        "    if confidence > args[\"confidence\"]:\n",
        "      # compute the (x, y) coordinates of the bounding box for the face\n",
        "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "      # extract the face ROI\n",
        "      face = image[startY:endY, startX:endX]\n",
        "      (fH, fW) = face.shape[:2]\n",
        "\n",
        "      # ensure the face width and height are sufficiently large\n",
        "      if ((fW < 20) or (fH < 20)):\n",
        "        continue\n",
        "      \n",
        "      faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
        "      embedder.setInput(faceBlob)\n",
        "      vec = embedder.forward()\n",
        "      # perform classification to recognize the face\n",
        "      preds = recognizer.predict_proba(vec)[0]\n",
        "      j = np.argmax(preds)\n",
        "      proba = preds[j]\n",
        "      name = le.classes_[j]\n",
        "\n",
        "      text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
        "      y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "      cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "      cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "\n",
        "      cv2.imshow(\"Video\", img)\n",
        "      # cv2.waitKey(0)\n",
        "\n",
        "  if (ord('q') == cv2.waitKey(10)):\n",
        "    exit(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksshhlmQNilq"
      },
      "source": [
        "print(\"Starting video stream...\\n\")\n",
        "\n",
        "rtsp_url = \"rtsp://192.168.1.6:8080/h264_pcm.sdp\"\n",
        "\n",
        "vs = VideoStream(rtsp_url).start()\n",
        "time.sleep(2.0)\n",
        "\n",
        "# Start FPS Throughput Estimator\n",
        "fps = FPS().start()\n",
        "\n",
        "# Loop over frames\n",
        "while True:\n",
        "  frame = vs.read()\n",
        "  frame = imutils.resize(frame, width = 600)\n",
        "  (h, w) = frame.shape[:2]\n",
        "\n",
        "  imageBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB = False, crop = False)\n",
        "\n",
        "  detector.setInput(imageBlob)\n",
        "  detections = detector.forward()\n",
        "\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "\n",
        "    if (confidence > 0.2):\n",
        "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "      face = frame[startY: endY, startX: endX]\n",
        "      (fH, fW) = face.shape[:2]\n",
        "\n",
        "      if ((fW < 20) or (fH < 20)):\n",
        "        continue\n",
        "      \n",
        "      faceBlob = cv2.dnn.blobFromImage(face, 1.0/255, (96, 96), (0, 0, 0), swapRB = True, crop = False)\n",
        "\n",
        "      embedder.setInput(faceBlob)\n",
        "      vec = embedder.forward()\n",
        "\n",
        "      preds = recognizer.predict_proba(vec)[0]\n",
        "      j = np.argmax(preds)\n",
        "      proba = preds[j]\n",
        "      name = le.classes_[j]\n",
        "\n",
        "      text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
        "      y = startY - 10 if (startY - 10 > 10) else (startY + 10)\n",
        "\n",
        "      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "      cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "  \n",
        "  fps.update()\n",
        "  cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "  key = cv2.waitKey(1) & 0xFF\n",
        "  if (key == ord('q') or key == ord('Q')):\n",
        "    break\n",
        "  \n",
        "fps.stop()\n",
        "\n",
        "print(\"Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
        "print(\"Approx. FPS: {:.2f}\".format(fps.fps()))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXqFAnVp6YPQ"
      },
      "source": [
        "# **Helper function: Converting `.pb` model to `.pbtxt` frozen graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_dgxSNsHFJ7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import gfile\n",
        "from google.protobuf import text_format\n",
        "\n",
        "with gfile.FastGFile('MobileFaceNet.pb', 'rb') as f:\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "\n",
        "        graph_def.ParseFromString(f.read())\n",
        "\n",
        "        tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "        tf.compat.v1.train.write_graph(graph_def, '/content', 'protobuf.pbtxt', as_text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqhHwKSeViVj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}